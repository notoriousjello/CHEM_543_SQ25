{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-blob\n",
      "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting azure-core>=1.30.0 (from azure-storage-blob)\n",
      "  Downloading azure_core-1.34.0-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting cryptography>=2.1.4 (from azure-storage-blob)\n",
      "  Downloading cryptography-45.0.3-cp37-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\final\\documents\\chem_543_sq25\\.venv\\lib\\site-packages (from azure-storage-blob) (4.13.2)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy>=1.17.0 (from opencv-python)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\final\\documents\\chem_543_sq25\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting requests>=2.21.0 (from azure-core>=1.30.0->azure-storage-blob)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\final\\documents\\chem_543_sq25\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-storage-blob) (1.17.0)\n",
      "Collecting cffi>=1.14 (from cryptography>=2.1.4->azure-storage-blob)\n",
      "  Downloading cffi-1.17.1-cp39-cp39-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=2.1.4->azure-storage-blob)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob)\n",
      "  Downloading charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 7.3/39.5 MB 34.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 17.0/39.5 MB 39.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.8/39.5 MB 45.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 47.4 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 11.6/11.6 MB 66.0 MB/s eta 0:00:00\n",
      "Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 77.9 MB/s eta 0:00:00\n",
      "Downloading azure_core-1.34.0-py3-none-any.whl (207 kB)\n",
      "Downloading cryptography-45.0.3-cp37-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/3.4 MB 66.7 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 15.9/15.9 MB 83.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, pycparser, pillow, numpy, isodate, idna, charset-normalizer, certifi, requests, pandas, opencv-python, cffi, cryptography, azure-core, azure-storage-blob\n",
      "\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [urllib3]\n",
      "   ---- -----------------------------------  2/17 [tzdata]\n",
      "   ---- -----------------------------------  2/17 [tzdata]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ------------------ ---------------------  8/17 [charset-normalizer]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [opencv-python]\n",
      "   ---------------------------- ----------- 12/17 [opencv-python]\n",
      "   ---------------------------- ----------- 12/17 [opencv-python]\n",
      "   ------------------------------ --------- 13/17 [cffi]\n",
      "   -------------------------------- ------- 14/17 [cryptography]\n",
      "   ----------------------------------- ---- 15/17 [azure-core]\n",
      "   ------------------------------------- -- 16/17 [azure-storage-blob]\n",
      "   ------------------------------------- -- 16/17 [azure-storage-blob]\n",
      "   ---------------------------------------- 17/17 [azure-storage-blob]\n",
      "\n",
      "Successfully installed azure-core-1.34.0 azure-storage-blob-12.25.1 certifi-2025.4.26 cffi-1.17.1 charset-normalizer-3.4.2 cryptography-45.0.3 idna-3.10 isodate-0.7.2 numpy-2.0.2 opencv-python-4.11.0.86 pandas-2.2.3 pillow-11.2.1 pycparser-2.22 pytz-2025.2 requests-2.32.3 tzdata-2025.2 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install azure-storage-blob opencv-python pandas pillow torch torchvision scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "930864c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads our needed packages\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf0841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped 743 defect regions.\n"
     ]
    }
   ],
   "source": [
    "# loads our csv that has the merged bounding box data\n",
    "csv_path = 'combined_defects.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# sets image folder path\n",
    "image_folder = 'Images'\n",
    "\n",
    "# loads image by image id\n",
    "def load_image(image_id, ext='.png'):\n",
    "    image_path = os.path.join(image_folder, f\"{image_id}{ext}\")\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    return Image.open(image_path).convert('RGB')\n",
    "\n",
    "# crops defect region to that stated in the bounding box\n",
    "def crop_defects(df):\n",
    "    crops = []\n",
    "    for idx, row in df.iterrows():\n",
    "        image_id = row['image_id']\n",
    "        x, y, w, h = int(row['BX']), int(row['BY']), int(row['Width']), int(row['Height'])\n",
    "        \n",
    "        try:\n",
    "            img = load_image(image_id)  # Load the full image\n",
    "            crop = img.crop((x, y, x + w, y + h))  # Crop box: (left, upper, right, lower)\n",
    "            crops.append({\n",
    "                'image_id': image_id,\n",
    "                'bbox': (x, y, w, h),\n",
    "                'crop': crop\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping defect at index {idx} in image '{image_id}': {e}\")\n",
    "    \n",
    "    return crops\n",
    "\n",
    "# executes cropping\n",
    "cropped_defects = crop_defects(df)\n",
    "print(f\"Cropped {len(cropped_defects)} defect regions.\")\n",
    "\n",
    "# # save cropped images to disk to double check the crop was correct\n",
    "# output_folder = 'defect_crops'\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# for i, item in enumerate(cropped_defects):\n",
    "#     filename = f\"{item['image_id']}_defect_{i}.png\"\n",
    "#     path = os.path.join(output_folder, filename)\n",
    "#     item['crop'].save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecf0c35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted embeddings for 743 defects.\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup model: pre-trained ResNet18, remove final classification layer\n",
    "model = resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # remove last fc layer\n",
    "model.eval()  # inference mode\n",
    "\n",
    "# 2. Image preprocessing for ResNet input\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
    "                         std=[0.229, 0.224, 0.225])    # ImageNet stds\n",
    "])\n",
    "\n",
    "# 3. Function to get embedding from a crop\n",
    "def get_embedding(crop_img):\n",
    "    input_tensor = preprocess(crop_img).unsqueeze(0)  # add batch dim\n",
    "    with torch.no_grad():\n",
    "        features = model(input_tensor)\n",
    "    features = features.squeeze().numpy()  # shape (512,)\n",
    "    return features\n",
    "\n",
    "# 4. Apply to all cropped defects\n",
    "features_list = []\n",
    "for item in cropped_defects:\n",
    "    crop_img = item['crop']\n",
    "    emb = get_embedding(crop_img)\n",
    "    features_list.append({\n",
    "        'image_id': item['image_id'],\n",
    "        'bbox': item['bbox'],\n",
    "        'embedding': emb\n",
    "    })\n",
    "\n",
    "print(f\"Extracted embeddings for {len(features_list)} defects.\")\n",
    "\n",
    "X = np.array([item['embedding'] for item in features_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f767de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defect counts per cluster:\n",
      "Counter({np.int32(1): 228, np.int32(0): 183, np.int32(4): 155, np.int32(3): 136, np.int32(2): 41})\n"
     ]
    }
   ],
   "source": [
    "# Set number of clusters (choose based on your domain knowledge or try different values)\n",
    "n_clusters = 5\n",
    "\n",
    "# Initialize and fit KMeans\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get cluster labels for each defect\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Add cluster labels back to your features_list for reference\n",
    "for i, item in enumerate(features_list):\n",
    "    item['cluster'] = labels[i]\n",
    "\n",
    "# Print how many defects per cluster\n",
    "from collections import Counter\n",
    "print(\"Defect counts per cluster:\")\n",
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d87d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustering results to defects_clustered.csv\n"
     ]
    }
   ],
   "source": [
    "output_rows = []\n",
    "for item in features_list:\n",
    "    image_id = item['image_id']\n",
    "    bx, by, w, h = item['bbox']\n",
    "    cluster = item['cluster']\n",
    "    output_rows.append({\n",
    "        'image_id': image_id,\n",
    "        'BX': bx,\n",
    "        'BY': by,\n",
    "        'Width': w,\n",
    "        'Height': h,\n",
    "        'Cluster': cluster\n",
    "    })\n",
    "\n",
    "df_out = pd.DataFrame(output_rows)\n",
    "df_out.to_csv('defects_clustered.csv', index=False)\n",
    "print(\"Saved clustering results to defects_clustered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86a61469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered image: clustered_images\\1_clustered.png\n",
      "Saved clustered image: clustered_images\\10_clustered.png\n",
      "Saved clustered image: clustered_images\\11_clustered.png\n",
      "Saved clustered image: clustered_images\\12_clustered.png\n",
      "Saved clustered image: clustered_images\\13_clustered.png\n",
      "Saved clustered image: clustered_images\\14_clustered.png\n",
      "Saved clustered image: clustered_images\\15_clustered.png\n",
      "Saved clustered image: clustered_images\\16_clustered.png\n",
      "Saved clustered image: clustered_images\\17_clustered.png\n",
      "Saved clustered image: clustered_images\\18_clustered.png\n",
      "Saved clustered image: clustered_images\\19_clustered.png\n",
      "Saved clustered image: clustered_images\\2_clustered.png\n",
      "Saved clustered image: clustered_images\\20_clustered.png\n",
      "Saved clustered image: clustered_images\\21_clustered.png\n",
      "Saved clustered image: clustered_images\\22_clustered.png\n",
      "Saved clustered image: clustered_images\\23_clustered.png\n",
      "Saved clustered image: clustered_images\\24_clustered.png\n",
      "Saved clustered image: clustered_images\\25_clustered.png\n",
      "Saved clustered image: clustered_images\\26_clustered.png\n",
      "Saved clustered image: clustered_images\\27_clustered.png\n",
      "Saved clustered image: clustered_images\\28_clustered.png\n",
      "Saved clustered image: clustered_images\\3_clustered.png\n",
      "Saved clustered image: clustered_images\\4_clustered.png\n",
      "Saved clustered image: clustered_images\\5_clustered.png\n",
      "Saved clustered image: clustered_images\\6_clustered.png\n",
      "Saved clustered image: clustered_images\\7_clustered.png\n",
      "Saved clustered image: clustered_images\\8_clustered.png\n",
      "Saved clustered image: clustered_images\\9_clustered.png\n"
     ]
    }
   ],
   "source": [
    "# Folder paths\n",
    "image_folder = 'Images'\n",
    "output_folder = 'clustered_images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define distinct colors for clusters (extend as needed)\n",
    "cluster_colors = [\n",
    "    'white', 'blue', 'green', 'orange', 'lime',\n",
    "    'cyan', 'black', 'yellow', 'purple', 'gray'\n",
    "]\n",
    "\n",
    "# Group defects by image for easier plotting\n",
    "from collections import defaultdict\n",
    "defects_by_image = defaultdict(list)\n",
    "for item in features_list:\n",
    "    defects_by_image[item['image_id']].append(item)\n",
    "\n",
    "# Draw bounding boxes with cluster colors on each image\n",
    "for image_id, defects in defects_by_image.items():\n",
    "    img_path = os.path.join(image_folder, f\"{image_id}.png\")  # Adjust extension if needed\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image not found for visualization: {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for defect in defects:\n",
    "        bx, by, w, h = defect['bbox']\n",
    "        cluster = defect['cluster']\n",
    "        color = cluster_colors[cluster % len(cluster_colors)]\n",
    "        # Draw rectangle (outline)\n",
    "        draw.rectangle([bx, by, bx + w, by + h], outline=color, width=3)\n",
    "    \n",
    "    # Save or show the image\n",
    "    out_path = os.path.join(output_folder, f\"{image_id}_clustered.png\")\n",
    "    img.save(out_path)\n",
    "    print(f\"Saved clustered image: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
